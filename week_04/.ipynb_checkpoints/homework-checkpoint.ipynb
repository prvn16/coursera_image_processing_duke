{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional programming exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import skimage\n",
    "from skimage import img_as_float, img_as_ubyte\n",
    "from skimage import io\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_1xc(imgs_list, titles_list, save_file=None):\n",
    "    cols = len(imgs_list)\n",
    "    i = 0\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=1, ncols=cols, figsize=(15,15))\n",
    "    for c in range(cols):\n",
    "        axes[c].imshow(imgs_list[i], cmap=\"gray\")\n",
    "        axes[c].set_title(titles_list[i], size=20)\n",
    "        axes[c].set_xticks([])\n",
    "        axes[c].set_yticks([])\n",
    "        i = i + 1\n",
    "    plt.tight_layout();\n",
    "    \n",
    "    if not (save_file == None):\n",
    "        filename = save_file + time.strftime(\"%Y%m%d_%H%M\") + \".png\"\n",
    "        fig.savefig(filename, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1\n",
    "Add Gaussian and salt-and-pepper noise with different parameters to an image of your choice. Evaluate what levels of noise you consider still acceptable for visual inspection of the image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from skimage.color import rgb2gray\n",
    "from skimage.util import random_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_o = io.imread(\"../lena512color.tiff\")\n",
    "img_o = rgb2gray(img_o)\n",
    "\n",
    "img_g = random_noise(img_o, mode=\"gaussian\", var=0.02)\n",
    "img_sp = random_noise(img_o, mode=\"s&p\", amount=0.05)\n",
    "\n",
    "ims = [img_o, img_g, img_sp]\n",
    "titles = [\"Original\", \"Gaussian\", \"Salt & Pepper\"]\n",
    "plot_1xc(ims, titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2\n",
    "Apply median filter to the images you obtained above. Change the window size of the filter and evaluate its relationship with the noise levels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from skimage.filters.rank import median\n",
    "from skimage.morphology import disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_g_dn = median(img_g, disk(3))\n",
    "img_sp_dn = median(img_sp, disk(3))\n",
    "\n",
    "ims = [img_o, img_g_dn, img_sp_dn]\n",
    "titles = [\"Original\", \"Median Gaussian\", \"Median Salt & Pepper\"]\n",
    "plot_1xc(ims, titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3\n",
    "Practice with Wiener filtering. Consider for example a Gaussian blurring (so you know exactly the H function) and play with different values of K for different types and levels of noise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage import color, data, restoration\n",
    "from scipy.signal import convolve2d as conv2\n",
    "from skimage.filters.rank import mean\n",
    "from skimage.filters import gaussian_filter\n",
    "\n",
    "from scipy import signal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_b = mean(img_o, disk(10))\n",
    "img_bn = random_noise(img_b, mode=\"gaussian\", var=0.0005)\n",
    "\n",
    "sigma = 4\n",
    "img_b2 = gaussian_filter(img_o, sigma, mode='nearest')\n",
    "img_b2n = random_noise(img_b2, mode=\"gaussian\", var=0.0005)\n",
    "\n",
    "img_n = random_noise(img_o, mode=\"gaussian\", var=0.005)\n",
    "\n",
    "psf = np.ones((5, 5))\n",
    "# psf[1:-1,1:-1] = 2\n",
    "# psf[2:-2,2:-2] = 3\n",
    "psf = psf/np.sum(psf)\n",
    "# print(psf, np.sum(psf))\n",
    "\n",
    "# img_w, _ = restoration.unsupervised_wiener(img_b2n, psf)\n",
    "# img_w = restoration.wiener(img_b, psf, 0.0825)\n",
    "# img_w = signal.wiener(img_b2n, (5, 5))\n",
    "img_w = signal.wiener(img_n, (5, 5))\n",
    "\n",
    "ims = [img_o, img_b2, img_n, img_w]\n",
    "titles = [\"Original\", \"Blurred\", \"Noisy\", \"Wiener\"]\n",
    "plot_1xc(ims, titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4\n",
    "Compare the results of non-local-means from the previous week (use for example the implementation in www.ipol.im) with those of Wiener filtering.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from skimage.restoration import nl_means_denoising\n",
    "# skimage.restoration.nl_means_denoising\n",
    "\n",
    "img_dn = nl_means_denoising(img_g, patch_size=7, patch_distance=11, h=0.05)\n",
    "\n",
    "ims = [img_o, img_g, img_dn]\n",
    "titles = [\"Original\", \"Gaussian\", \"Nonlocal\"]\n",
    "plot_1xc(ims, titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 5\n",
    "Blur an image applying local averaging (select different block sizes and use both overlapping and not overlapping blocks). Apply to it non-local means. Observe if it helps to make the image better. Could you design a restoration algorithm, for blurry images, that uses the same concepts as non-local-means?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_db = nl_means_denoising(img_b, patch_size=5, patch_distance=11, h=0.25)\n",
    "\n",
    "ims = [img_o, img_b, img_db]\n",
    "titles = [\"Original\", \"Blurred\", \"Nonlocal\"]\n",
    "plot_1xc(ims, titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 6\n",
    "Make multiple (N) copies of the same image (e.g., N=10). To each copy, apply a random rotation and add some random Gaussian noise (you can test different noise levels). Using a registration function like imregister in Matlab, register the N images back (use the first image as reference, so register the other N-1 to it), and then average them. Observe if you manage to estimate the correct rotation angles and if you manage to reduce the noise. Note: Registration means that you are aligning the images again, see for example http://www.mathworks.com/help/images/ref/imregister.html or http://en.wikipedia.org/wiki/Image_registration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The solution follows this code: http://nbviewer.jupyter.org/github/scikit-image/scikit-image-demos/blob/master/pano/pano.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from skimage import io, transform\n",
    "from skimage.color import rgb2gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_1 = transform.rotate(img_o, 30)\n",
    "img_1 = transform.rescale(img_1, .75)\n",
    "img_1 = random_noise(img_1, mode=\"gaussian\", var=0.005)\n",
    "\n",
    "print(img_o.shape, img_1.shape)\n",
    "\n",
    "ims = [img_o, img_1]\n",
    "titles = [\"Original\", \"Rotated 30\"]\n",
    "plot_1xc(ims, titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from skimage.feature import ORB, match_descriptors, plot_matches\n",
    "image0 = img_o\n",
    "image1 = img_1\n",
    "\n",
    "orb = ORB(n_keypoints=400, fast_threshold=0.05)\n",
    "\n",
    "orb.detect_and_extract(image0)\n",
    "keypoints1 = orb.keypoints\n",
    "descriptors1 = orb.descriptors\n",
    "\n",
    "orb.detect_and_extract(image1)\n",
    "keypoints2 = orb.keypoints\n",
    "descriptors2 = orb.descriptors\n",
    "\n",
    "matches12 = match_descriptors(descriptors1, descriptors2, cross_check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(15, 15))\n",
    "plot_matches(ax, image0, image1, keypoints1, keypoints2, matches12)\n",
    "ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from skimage.transform import ProjectiveTransform\n",
    "from skimage.measure import ransac\n",
    "from skimage.feature import plot_matches\n",
    "\n",
    "# Select keypoints from the source (image to be registered)\n",
    "# and target (reference image)\n",
    "src = keypoints2[matches12[:, 1]][:, ::-1]\n",
    "dst = keypoints1[matches12[:, 0]][:, ::-1]\n",
    "\n",
    "model_robust, inliers = ransac((src, dst), ProjectiveTransform,\n",
    "                               min_samples=4, residual_threshold=1, max_trials=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(15, 15))\n",
    "plot_matches(ax, image0, image1, keypoints1, keypoints2, matches12[inliers])\n",
    "ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from skimage.transform import SimilarityTransform\n",
    "\n",
    "r, c = image1.shape[:2]\n",
    "\n",
    "# Note that transformations take coordinates in (x, y) format,\n",
    "# not (row, column), in order to be consistent with most literature\n",
    "corners = np.array([[0, 0],\n",
    "                    [0, r],\n",
    "                    [c, 0],\n",
    "                    [c, r]])\n",
    "\n",
    "# Warp the image corners to their new positions\n",
    "warped_corners = model_robust(corners)\n",
    "\n",
    "# Find the extents of both the reference image and the warped\n",
    "# target image\n",
    "all_corners = np.vstack((warped_corners, corners))\n",
    "\n",
    "corner_min = np.min(all_corners, axis=0)\n",
    "corner_max = np.max(all_corners, axis=0)\n",
    "\n",
    "output_shape = (corner_max - corner_min)\n",
    "output_shape = np.ceil(output_shape[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from skimage.color import gray2rgb\n",
    "from skimage.exposure import rescale_intensity\n",
    "from skimage.transform import warp\n",
    "\n",
    "offset = SimilarityTransform(translation=-corner_min)\n",
    "\n",
    "image0_ = warp(image0, offset.inverse,\n",
    "               output_shape=output_shape, cval=-1)\n",
    "\n",
    "image1_ = warp(image1, (model_robust + offset).inverse,\n",
    "               output_shape=output_shape, cval=-1)\n",
    "\n",
    "print(image0_.shape, image1_.shape)\n",
    "plot_1xc([image0_, image1_],[\"Warp 1\", \"Warp 2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 7\n",
    "Apply JPEG compression to an image, with high levels of compression such that the artifacts are noticeable. Can you apply any of the techniques learned so far to enhance the image, for example, reduce the artifacts or the blocking effects? Try as many techniques as you can and have time to do.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 8\n",
    "Apply any image predictor as those we learned in Week 2. Plot the histogram of the prediction error. Try to fit a function to it to learn what type of distribution best first the prediction error.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
